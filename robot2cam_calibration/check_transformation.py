"""A file to visually check the result of camera coordinate to robot base transformation

"""

# The MIT License (MIT)
#
# Copyright (c) 2016 GTRC.
#
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in all
# copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
# SOFTWARE.

import cv2
import os
import numpy as np
import camera
import json
import track_grid
import re
import compute_transformations


def check_transformation(r2c_calibration, robot_data, ImageFolder, ResultFolder, cam_calibration):
    """Plots transformed 3D world points onto camera image

            Args:
                r2c_calibration (str): JSON file generated by
                                   compute_transformations
                robot_data (str): The filename of the robot poses in the images.
                                  This file should be a json file with fields:
                                  'time', 'tcp2robot', 'camera2grid'.
                                  'tcp2robot' and 'camera2grid' should be lists
                                  of lists, with each individual list being a
                                  Rodrigues vector
                                  (x,y,z,3 element rotation vector/axis-angle).
                                  Linear distance must be consistent with each
                                   other and the camera intrinsic and
                                   distortion data (mm are recommended).
                                   Angular distances must be in radians.
                ImageFolder (str): The name of the folder to read images from
                ResultFolder (str): The name of the folder to save the output images in
                camera calibration (str): The JSON file holding the camera
                                          calibration data as generated by:
                                          https://pypi.python.org/pypi/camera_calibration/
            """
    if len(ResultFolder) and (ResultFolder[0] == '/' or ResultFolder[0] == '\\'):
        ResultFolder = ResultFolder[1:]
    if len(ResultFolder) and (ResultFolder[-1] == '/' or ResultFolder[-1] == '\\'):
        ResultFolder = ResultFolder[:-1]

    if len(ImageFolder) and (ImageFolder[0] == '/' or ImageFolder[0] == '\\'):
        ImageFolder = ImageFolder[1:]
    if len(ImageFolder) and (ImageFolder[-1] == '/' or ImageFolder[-1] == '\\'):
        ImageFolder = ImageFolder[:-1]

    with open(cam_calibration,'r') as file:
        calib_dict = json.load(file)
        intrinsic = calib_dict['instrinsic']
        distortion = calib_dict['distortion']
        print("Loaded camera calibration data from {}".format(calib_dict['time']))

    with open(robot_data, 'r') as file:
        robot_dict = json.load(file)
        # nx6 arrays x,y,z,axis-angle:
        tcp2robot = robot_dict['tcp2robot']
        camera2target = robot_dict['camera2grid']
        print("Loaded calibration data from {}".format(robot_dict['time']))

    with open(r2c_calibration, 'r') as file:
        r2c_dict = json.load(file)
        # nx6 arrays x,y,z,axis-angle:
        tcp2target = r2c_dict['tcp2target']['Tmatrix']
        cam2rob = r2c_dict['cam2rob']['Tmatrix']
        print("Loaded calibration results from {}".format(r2c_dict['time']))

    target_directory = os.path.join(os.getcwd(), ImageFolder)
    directory_out = os.path.join(os.getcwd(), ResultFolder)
    file_names = os.listdir(target_directory)
    if not os.path.exists(directory_out):
        os.makedirs(directory_out)

    axis_length = 250
    axis = np.float32([[0,0,0],[axis_length, 0, 0], [0, axis_length, 0],
                                [0, 0, axis_length]]).reshape(-1, 3)

    number_found = 0

    # Change rotation matrix into rotation vector
    # for i in range(Rotm.shape[0]):
    #     rvec, jac = cv2.Rodrigues(Rotm[i])
    #     image_points[i], jac = cv2.projectPoints(axis, rvec, Tvec[i], intrinsic,
    #                                              distortion)
    for image_file in sort_nicely(file_names):
        image_file = os.path.join(target_directory, image_file)

        # Try to read in image as gray scale
        img = cv2.imread(image_file, 0)

        # If the image_file isn't an image, move on
        if img is not None:
            img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)
            labels = ['base_est','tcp_est','target_est','target_measured']
            tcp_est = np.matmul(cam2rob,tcp2robot[number_found])
            target_est = np.matmul(tcp_est,tcp2target)
            coordinates = [cam2rob, tcp_est,target_est,camera2target]
            for j in range(coordinates.shape[0]):
                cam2target = coordinates[j]
                rvec, jac = cv2.Rodrigues(cam2target[0:3,0:3])
                image_points, jac = cv2.projectPoints(axis, rvec, cam2target[0:3,3],
                                                         intrinsic,
                                                         distortion)
                img = track_grid.draw_axes(image_raw=img, corners=image_points[0],
                                               image_points=image_points[1:], label=labels[j])
            cv2.imwrite(os.path.join(ResultFolder, "result" + str(number_found) + ".jpg"), img)
            print("finished processing Image {}".format(image_file))
            number_found += 1
    print("Done processing all images")


# http://stackoverflow.com/questions/4623446/how-do-you-sort-files-numerically
def tryint(s):
    try:
        return int(s)
    except:
        return s

def alphanum_key(s):
    """ Turn a string into a list of string and number chunks.
        "z23a" -> ["z", 23, "a"]
    """
    return [ tryint(c) for c in re.split('([0-9]+)', s) ]

def sort_nicely(l):
    """ Sort the given list in the way that humans expect.
    """
    return sorted(l, key=alphanum_key)
# UR
# Rotm = np.matrix([[-.50634,.74773,-.42956],[.85721,.49064,-.15638],[.09383,-.44741,-.88939]])
# Tvec = np.array([.41163,.25832,1])

# Test
# Rotm = np.matrix([[1.000, 0.015, 0.001],[-0.015, 0.991, 0.131],[0.001, -0.131, 0.991]])
# Tvec = np.array([-0.355, 0.046, 2.189])
#
# Test2
# [0.977 -0.202 -0.063 0.047]
# [0.183 0.957 -0.223 0.081]
# [0.106 0.206 0.973 2.221]
# [0.000 0.000 0.000 1.000]
# Rotm = np.array([
#     [[0.977, -0.202, -0.063],[0.183, 0.957, -0.223],[0.106, 0.206, 0.973]],
#     [[0.977, -0.202, -0.063],[0.183, 0.957, -0.223],[0.106, 0.206, 0.973]]
# ])
# Tvec = np.array([
#     [0.047, 0.081, 2.221],
#     [0.7170, 0.2065, 2.2937]
# ])

# with axis angle
#Rotm = np.matrix([[-0.0010,   -0.9984,   -0.0558],[0.9995,    0.0009,   -0.0328],[0.0328,   -0.0558,    0.9979]])
#Tvec = np.array([0.0554,   -0.2315,   -0.0225])

# manual guess
#Rotm = np.matrix([[-0.707,   0.707,   0.0],[0.0,   0.0,   -1.0],[-0.707,   -0.707,    0.0]])
#Tvec = np.array([0.1,   0.35,   1.0])

# measure manual guess
# Rotm = np.matrix([[1.0,0.0,0.0],[0.0,1.0,0.0],[0.0,0.0,1.0]])
# Rotm = np.matrix([[-0.707,   0.707,   0.0],[0.0,   0.0,   -1.0],[-0.707,   -0.707,    0.0]])
# Tvec = np.array([0.2,   0.75,   2.0])

# Rotm = np.array([
#     [[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0]],
#     [[-0.707, 0.707, 0.0], [0.0, 0.0, -1.0], [-0.707, -0.707, 0.0]],
#     [[0.1419, -0.5214, -0.8412], [-0.8623, -0.4826, 0.1536 ], [-0.4861, 0.7036, -0.5181]],
#     [[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0]]
# ])
# Tvec = np.array([
#     [0, 0, 0],
#     [0.2, 0.75, 2.0],
#     [0.3517,   -0.1479,   1.2312],
#     [0.1517,   -0.8979,   -0.3688]
# ])

# row1: grid from track grid
# row2: door from EBT
# row3: approx tcp from mjs guess: row1*tcp
# row4: inverse transform to base via row3:
# row5: estimate from calibration software

# Rotm = np.array([
#     [[-0.00500405, 0.99998434, 0.0025046],
#      [-0.9306746, -0.00374094, -0.36582892],
#      [-0.36581382, -0.00416159, 0.93067875]],
#     [[0.977, -0.178, -0.121],
#      [0.136, 0.946, -0.294],
#      [0.167, 0.270, 0.948]],
#     [[- 0.00500405, -0.99998434, -0.00250460000000012],
#      [- 0.9306746, 0.00374093999999996, 0.36582892],
#      [- 0.36581382, 0.00416159000000011, -0.93067875]],
#     [[-0.659927435608819, 0.751329313735808, -0.0001893009399004],
#      [0.199371042478852, 0.174873921787055, -0.964194121183759],
#      [-0.72439420933552, -0.636335894927072, -0.265197405236951]],
#     np.eye(3)
# ])
# Tvec = np.array([
#     [151.48231455772967, -45.84279051621655, 1140.7020382437486],
#     [-38.0, -202.0, 2235.0],
#     [250.55, -218.392, 1072.610],
#     [75.79, 552.50, 1656.20],
#     [154.61, 156.377, 2032.33]
# ])

guess_tcp2target = np.array([
            [
                0.9982463218583976,
                -0.05914679682431312,
                -0.002436661980057513,
                -197.33352185827397
            ],
            [
                -0.059137624424438165,
                -0.998243061287316,
                0.0036785824935447356,
                112.55747772489642
            ],
            [
                -0.002649957285642191,
                -0.003528033042807774,
                -0.9999902653072344,
                6.914867237505867
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ])
tcp2robot =         [[
            0.1535513220283944,
            0.3681083737882555,
            0.8978855797329478,
            -1.9105306547966427,
            -0.7131508073189232,
            -1.7147285607488287
        ]]
i = 0
guess_cam2rob = np.array([
            [
                -0.7026499558759214,
                0.711061772870129,
                -0.0259652589117656,
                155.70940950205338
            ],
            [
                0.028947565394322416,
                -0.00789462021461107,
                -0.999549755354584,
                746.7496373291195
            ],
            [
                -0.7109466069722165,
                -0.7030852225260154,
                -0.015036352624107074,
                1471.4252938788886
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ])
guess_cam2tcp = np.matmul(guess_cam2rob, compute_transformations.vector2mat(np.concatenate(
    (1000 * np.array(tcp2robot[i][:3]), np.array(tcp2robot[i][3:])))))
guess_cam2target = np.matmul(guess_cam2tcp, guess_tcp2target)

supermatrix2 = np.array([[
    guess_cam2rob,
    guess_cam2target,
    guess_cam2tcp
]])

# origin = np.array([[1.0,0.0,0.0,285.0],[0.0,-1.0,0.0,175.0],[0.0,0.0,-1.0,2400.0],[0.0,0.0,0.0,1.0]])
origin = np.array([
            [
                0.9998025356664438,
                -0.019780052283439018,
                0.0019076704680500796,
                231.17221360064747
            ],
            [
                -0.019795016108877638,
                -0.9997706528765354,
                0.008173064546130104,
                197.6840491635405
            ],
            [
                0.001745569305277339,
                -0.008209213025031869,
                -0.9999647802844408,
                2341.614620189591
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ])
tcp = np.array([
            [
                0.999444897377233,
                0.0320210899676026,
                0.009194939037271596,
                -2.8121368699077345
            ],
            [
                0.03278013666306641,
                -0.9944614457812451,
                -0.09985937860324604,
                7.019983327370265
            ],
            [
                0.005946406222512091,
                0.1001053577585258,
                -0.9949590733296895,
                190.34774993582965
            ],
            [
                0.0,
                0.0,
                0.0,
                1.0
            ]
        ])
arm1 = np.matmul(np.matmul(origin,compute_transformations.vector2mat(np.array([-708.9298779,11.77962794,0.03923676471,0.000174451419,-0.0003487216127,-0.0001730138384]))),tcp)
arm2 = np.matmul(np.matmul(origin,compute_transformations.vector2mat(np.array([-708.9298779,11.77962794,0.03923676471,0.000174451419,-0.0003487216127,-0.0001730138384]))),tcp)
arm3 = np.matmul(np.matmul(origin,compute_transformations.vector2mat(np.array([-708.8530908,335.7374385,-131.5951415,-0.1829842155,0.05194162653,0.08295446543]))),tcp)

# arm1 = np.array(
#     [[ 0.9998,    0.0098,   -0.0201,   -0708.9],
#      [-0.0100,    0.9999,   -0.0098,    0011.8],
#      [ 0.0200,    0.0100,    0.9998,    0.0000],
#      [      0,         0,         0,    1.0000]])
# arm2 = np.array(
#     [[0.9952, -0.0871, 0.0440, -0708.8],
#      [0.0776,0.9799,0.1838,0335.7],
#      [-0.0591, -0.1795,0.9820, -0131.6],
#      [0,0,0,1.0000]])
# arm3 = np.array(
#     [[-0.6258,0.0774, -0.7761, -0574.3],
#      [0.6800,0.5416, -0.4943,0318.9],
#      [0.3821, -0.8370, -0.3916, -0288.7],
#      [0,0,0,1.0000]])

supermatrix3 = np.array([
    [
        origin
        ,arm1
        # ,np.matmul(origin,arm1)
    ],
    [
        origin
        ,arm2
        # , np.matmul(origin, arm2)
    ],
    [
        origin
        ,arm3
        # , np.matmul(origin, arm3)
    ]
])

# grid2tcp = np.array(
#     [[1.0000,0,0,185.0000],
#      [0,-1.0000,-0.0000,100.0000],
#      [0,0.0000,-1.0000,0],
#      [0,0,0,1.0000]]
# )

# with open('../examples/gridFinding.json', 'r') as grid_json:
#     json_dictionary = json.load(grid_json)
#
# cam2grid = np.array(json_dictionary['camera2grid'])
# base2tcp = np.array(json_dictionary['tcp2robot'])
#
# cam2gridT = np.zeros((cam2grid.shape[0], 4, 4))
# base2tcpT = np.zeros((cam2grid.shape[0], 4, 4))
#
# for i in range(cam2grid.shape[0]):
#     [cam2gridRot, _] = cv2.Rodrigues((cam2grid[i][3:]))
#     translation = np.array([cam2grid[i][:3]])
#     cam2gridT[i] = np.concatenate((np.concatenate((cam2gridRot, translation.T), axis=1),np.array([[0,0,0,1]])),axis=0)
#
# for i in range(cam2grid.shape[0]):
#     [cam2tcpRot, _] = cv2.Rodrigues((base2tcp[i][3:]))
#     translation = np.array([base2tcp[i][:3]])*1000
#     base2tcpT[i] = np.concatenate((np.concatenate((cam2tcpRot, translation.T), axis=1),np.array([[0,0,0,1]])),axis=0)
#
# cam2tcpT = np.matmul(cam2gridT,grid2tcp)
#
# tcp2baseT = np.zeros(base2tcpT.shape)
# for i in range(base2tcpT.shape[0]):
#     tcp2baseT[i] = np.linalg.inv(base2tcpT[i])
#
# cam2baseT = np.matmul(cam2tcpT,tcp2baseT)
#
# supermatrix = np.zeros((cam2baseT.shape[0],3,4,4))
# supermatrix[:,0] = cam2baseT
# supermatrix[:,1] = cam2tcpT
# supermatrix[:,2] = cam2gridT

ImageFolder = 'Images1'
ResultFolder = 'Result'
rows = 7
cols = 8
space = 25.4
intrinsic = np.array([[2462.345193638386,0.0,1242.6269086495981],[0.0,2463.6133832534606,1014.3609261368764],
                     [0.0,0.0,1.0]])
distortion = np.array([[-0.3954032063765203,0.20971494160750948,0.0008056336338866635,9.237725225524615e-05,
                       -0.06042030845477194]])
check_transformation(supermatrix3,ImageFolder,ResultFolder,rows,cols,space,intrinsic,distortion)


